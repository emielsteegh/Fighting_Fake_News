{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sia = SIA()\n",
    "\n",
    "import nltk\n",
    "#file for punkt splitter\n",
    "nltk.download('punkt');\n",
    "#file for vader sentiment\n",
    "nltk.download('vader_lexicon');\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=20,20\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Data loading/collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_len = 200\n",
    "mask_value = -10\n",
    "max_len = 0\n",
    "\n",
    "def text_to_sentiments(text):\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    scores = [ sia.polarity_scores(s)['compound'] for s in sentences] #list of compound score per sentence\n",
    "    if len(scores) < series_len:\n",
    "        t  = series_len - len(scores)\n",
    "        scores = np.pad(scores, (t, 0), mode='constant', constant_values=mask_value)\n",
    "    else:\n",
    "        scores = scores[(-1*series_len):]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Couldn't find data, will start building it now...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>veracity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  scores veracity\n",
       "0      [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        T\n",
       "1      [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        T\n",
       "2      [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        T\n",
       "3      [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        T\n",
       "4      [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        T\n",
       "...                                                  ...      ...\n",
       "44893  [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        F\n",
       "44894  [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        F\n",
       "44895  [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        F\n",
       "44896  [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        F\n",
       "44897  [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10...        F\n",
       "\n",
       "[44898 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(os.path.join('out', 'truefake_series.csv'))\n",
    "    print('Succesfully loaded data')\n",
    "except FileNotFoundError:\n",
    "    print('ERROR: Couldn\\'t find data, will start building it now...')\n",
    "    dataset_path_true = os.path.join(\"sources\", \"ISOT\", \"True.csv\")\n",
    "    dataset_path_fake = os.path.join(\"sources\", \"ISOT\", \"Fake.csv\")\n",
    "\n",
    "    dataset_load_true = pd.read_csv(dataset_path_true, encoding='utf-8') # make sure to use the right encoding\n",
    "    dataset_load_fake = pd.read_csv(dataset_path_fake, encoding='utf-8') \n",
    "    \n",
    "    df_T = pd.DataFrame(columns = ['scores', 'veracity'])\n",
    "    df_F = pd.DataFrame(columns = ['scores', 'veracity'])\n",
    "\n",
    "    df_T['scores'] = dataset_load_true.text.apply(text_to_sentiments)\n",
    "    df_T['veracity'] = 'T'\n",
    "\n",
    "    df_F['scores'] = dataset_load_fake.text.apply(text_to_sentiments)\n",
    "    df_F['veracity'] = 'F'\n",
    "\n",
    "    df = pd.concat([df_T,df_F], ignore_index=True)\n",
    "    df = df[df['scores'].map(lambda d: len(d)) > 0]\n",
    "    df.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df_T,df_F], ignore_index=True)\n",
    "    df = df[df['scores'].map(lambda d: len(d)) > 0]\n",
    "    df.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    df.to_csv(os.path.join('out', 'truefake_series.csv'), index=False)\n",
    "    \n",
    "finally:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_in, test_size, shuffle=True):\n",
    "    \n",
    "    if shuffle:\n",
    "        df_in = df_in.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    mask_test = np.random.rand(len(df_in)) < test_size # the sample is large enough to probably not care about proper division\n",
    "    \n",
    "    train = df_in[~mask_test]\n",
    "    test = df_in[mask_test]\n",
    "    \n",
    "    X_train = train['scores'].tolist()\n",
    "    y_train = train['veracity'].tolist()\n",
    "    \n",
    "    X_test = test['scores'].tolist()\n",
    "    y_test = test['veracity'].tolist()\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  26964 26964 \n",
      "test:  17934 17934 \n",
      "test/total: 0.399\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(160)\n",
    "random.seed(160)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(df, test_size = 0.4)\n",
    "print(\"train: \",len(X_train), len(y_train),\n",
    "     \"\\ntest: \",len(X_test), len(y_test),\n",
    "     \"\\ntest/total: {:0.3f}\".format(len(X_test)/(len(X_test)+len(X_train)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-dbb333efc81c>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-dbb333efc81c>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model.add(\n",
    "    Embedding(input_dim=series_len,\n",
    "              input_length=series_len, #??\n",
    "              output_dim=1 # True or False as a -1 to 1?\n",
    "    \n",
    "    )\n",
    ")\n",
    "model.add(Masking(mask_value=mask_value)) # 200 [series len] timesteps (sentences) with 1 feature (sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_notebook",
   "language": "python",
   "name": "thesis_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
