{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sia = SIA()\n",
    "\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "#file for punkt splitter\n",
    "nltk.download('punkt');\n",
    "#file for vader sentiment\n",
    "nltk.download('vader_lexicon');\n",
    "\n",
    "#wordnet lemmatization\n",
    "nltk.download('wordnet')\n",
    "#more for preprocessing\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=20,20\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1: Load the dataset <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path_true = os.path.join(\"sources\", \"ISOT\", \"True.csv\")\n",
    "dataset_path_fake = os.path.join(\"sources\", \"ISOT\", \"Fake.csv\")\n",
    "\n",
    "df_true = pd.read_csv(dataset_path_true, encoding='utf-8') # make sure to use the right encoding\n",
    "df_fake = pd.read_csv(dataset_path_fake, encoding='utf-8') \n",
    "\n",
    "dfm_true = df_true.head()\n",
    "dfm_fake = df_fake.head()\n",
    "\n",
    "display(dfm_true)\n",
    "display(dfm_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of documents in corpus:  44898\n"
     ]
    }
   ],
   "source": [
    "corpus_texts = [] # list of all documents (by entire body)\n",
    "\n",
    "#corpus_texts = df_true['text'].tolist() + df_fake['text'].tolist() \n",
    "corpus_texts = df_true['text'].tolist() + df_fake['text'].tolist() \n",
    "\n",
    "print(\"amount of documents in corpus: \", len(corpus_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X: Creating the new Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('gensim', '02', 'tfidf_corpus.pickle'), 'rb') as f: tfidf_corpus_texts = pickle.load(f)\n",
    "    \n",
    "lda_tfidf_model = gensim.models.LdaMulticore.load(os.path.join(\"gensim\", \"02\", \"lda_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_16_input (InputLayer [(None, 100, 1)]          0         \n",
      "_________________________________________________________________\n",
      "masking_16 (Masking)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 100, 50)           30200     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 100, 25)           7600      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 100, 25)           0         \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 10)                1440      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 80,051\n",
      "Trainable params: 80,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(os.path.join('keras', 'LSTM_tree'))\n",
    "\n",
    "pre_activation_layer_name = 'dense_16'\n",
    "\n",
    "model_pre_activation = keras.Model(inputs=model.input,\n",
    "                                   outputs=model.get_layer(pre_activation_layer_name).output)\n",
    "\n",
    "model_pre_activation.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617904543876648\n"
     ]
    }
   ],
   "source": [
    "series_len = 100\n",
    "mask_value = -10\n",
    "max_len = 0\n",
    "\n",
    "def text_to_sequence(text):\n",
    "    # feed corpus_texts[entry], returns 100 units long -10 padded sequence of sentiment data\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    scores = [ sia.polarity_scores(s)['compound'] for s in sentences] #list of compound score per sentence\n",
    "    \n",
    "    if len(scores) < series_len:\n",
    "        t  = series_len - len(scores)\n",
    "        scores = np.pad(scores, (t, 0), mode='constant', constant_values=mask_value)\n",
    "        scores = scores.reshape((series_len, 1))\n",
    "    else:\n",
    "        scores = np.array(scores[(-1*series_len):])\n",
    "        scores = scores.reshape((series_len, 1))\n",
    "        \n",
    "    return scores\n",
    "\n",
    "def scores_to_sequence(scores):\n",
    "    if len(scores) < series_len:\n",
    "        t  = series_len - len(scores)\n",
    "        scores = np.pad(scores, (t, 0), mode='constant', constant_values=mask_value)\n",
    "        scores = scores.reshape((series_len, 1))\n",
    "    else:\n",
    "        scores = np.array(scores[(-1*series_len):])\n",
    "        scores = scores.reshape((series_len, 1))\n",
    "    return scores\n",
    "\n",
    "\n",
    "sample_sentences = split_sentences(corpus_texts[2])\n",
    "sample_scores = get_scores(sample_sentences)\n",
    "sample_sequence = scores_to_sequence(sample_scores)\n",
    "sample_prediction = float(model(np.array([sample_sequence])))\n",
    "\n",
    "print(sample_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 354 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LSTM_pred': 0.617904543876648,\n",
       " 'count': 17.0,\n",
       " 'mean': -0.01017647058823531,\n",
       " 'std': 0.45047517208139753,\n",
       " 'min': -0.6808,\n",
       " '25%': -0.2732,\n",
       " '50%': 0.0,\n",
       " '75%': 0.3818,\n",
       " 'max': 0.7269}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_topics = 15\n",
    "\n",
    "def split_sentences(article_text):\n",
    "    \"\"\"Takes a string, returns a list of its individual sentences ()\"\"\"\n",
    "    return pd.Series(nltk.tokenize.sent_tokenize(article_text))\n",
    "\n",
    "def get_scores(text: list, method='VADER'):\n",
    "    if method == 'VADER':\n",
    "        scores = text.apply(lambda s: sia.polarity_scores(s)['compound']) #list of compound score per sentence\n",
    "    else:\n",
    "        scores = None\n",
    "\n",
    "    return scores\n",
    "\n",
    "def sentiment_stats(doc):\n",
    "    doc_sentence_list = split_sentences(doc)\n",
    "    sentiments = get_scores(doc_sentence_list)\n",
    "    sequence = scores_to_sequence(sentiments)\n",
    "    output = {'LSTM_pred' : float(model(np.array([sequence])))}\n",
    "    output.update(sentiments.describe().to_dict())\n",
    "    return (output)\n",
    "\n",
    "\n",
    "sentiment_stats(corpus_texts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T0': 0, 'T1': 0, 'T2': 0, 'T3': 0, 'T4': 0, 'T5': 0.54721564, 'T6': 0, 'T7': 0, 'T8': 0, 'T9': 0, 'T10': 0, 'T11': 0, 'T12': 0, 'T13': 0.3566922, 'T14': 0, 'Veracity': 1, 'LSTM_pred': 0.617904543876648, 'count': 17.0, 'mean': -0.01017647058823531, 'std': 0.45047517208139753, 'min': -0.6808, '25%': -0.2732, '50%': 0.0, '75%': 0.3818, 'max': 0.7269}\n",
      "Wall time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stat_cols = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'LSTM_pred']\n",
    "topic_cols = [('T'+str(x)) for x in range(0, num_topics)]+['Veracity']\n",
    "\n",
    "# text to list of topic scores\n",
    "\n",
    "def docid_to_row(doc_id):\n",
    "    new_row = dict.fromkeys(topic_cols , 0)\n",
    "    \n",
    "    new_row.update(sentiment_stats(corpus_texts[doc_id])) # add the sentiment key and value pairs\n",
    "    \n",
    "    for index, score in lda_tfidf_model[tfidf_corpus_texts[doc_id]]: # update the topic distributions\n",
    "        new_row['T'+str(index)] = score\n",
    "        \n",
    "    if(doc_id<21417): # the first 21417 items in the DB are \n",
    "        new_row['Veracity'] = 1\n",
    "        \n",
    "    return(new_row)\n",
    "\n",
    "print(docid_to_row(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building table done!.998%"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>LSTM_pred</th>\n",
       "      <th>T0</th>\n",
       "      <th>...</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>Veracity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.076147</td>\n",
       "      <td>0.402857</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>-0.077025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.31820</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.830285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855568</td>\n",
       "      <td>0.054737</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.486143</td>\n",
       "      <td>-0.8625</td>\n",
       "      <td>-0.292400</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.34000</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.331971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776423</td>\n",
       "      <td>0.143212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.010176</td>\n",
       "      <td>0.450475</td>\n",
       "      <td>-0.6808</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.38180</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.617905</td>\n",
       "      <td>0.047824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.029581</td>\n",
       "      <td>0.438841</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>-0.382650</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.35045</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.571730</td>\n",
       "      <td>0.179278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.047153</td>\n",
       "      <td>0.327357</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>-0.156025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.26705</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.785731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      mean       std     min       25%     50%      75%     max  \\\n",
       "0   30.0  0.076147  0.402857 -0.6369 -0.077025  0.0000  0.31820  0.9062   \n",
       "1   21.0  0.018648  0.486143 -0.8625 -0.292400  0.0772  0.34000  0.7531   \n",
       "2   17.0 -0.010176  0.450475 -0.6808 -0.273200  0.0000  0.38180  0.7269   \n",
       "3   16.0 -0.029581  0.438841 -0.6249 -0.382650  0.0000  0.35045  0.7430   \n",
       "4   40.0  0.047153  0.327357 -0.6124 -0.156025  0.0000  0.26705  0.6249   \n",
       "\n",
       "   LSTM_pred        T0  ...   T6        T7   T8   T9       T10  T11  T12  \\\n",
       "0   0.830285  0.000000  ...  0.0  0.000000  0.0  0.0  0.026417  0.0  0.0   \n",
       "1   0.331971  0.000000  ...  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0   \n",
       "2   0.617905  0.047824  ...  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0   \n",
       "3   0.571730  0.179278  ...  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0   \n",
       "4   0.785731  0.000000  ...  0.0  0.051978  0.0  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "        T13       T14  Veracity  \n",
       "0  0.855568  0.054737       1.0  \n",
       "1  0.776423  0.143212       1.0  \n",
       "2  0.342261  0.000000       1.0  \n",
       "3  0.280279  0.000000       1.0  \n",
       "4  0.842692  0.000000       1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 22min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_topic_sentiment = None\n",
    "df_topic_sentiment = pd.DataFrame(columns=stat_cols+topic_cols)\n",
    "\n",
    "count_texts = len(corpus_texts)\n",
    "for doc_id in range(count_texts):\n",
    "    df_topic_sentiment = df_topic_sentiment.append(docid_to_row(doc_id), ignore_index=True)\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str(\"current progress: {}%\".format(str(np.round(doc_id/count_texts*100, 3)))))\n",
    "\n",
    "sys.stdout.write('\\r')\n",
    "sys.stdout.write('building table done!')\n",
    "display(df_topic_sentiment.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sentiment.to_csv(os.path.join('out','everything.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_notebook",
   "language": "python",
   "name": "thesis_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
