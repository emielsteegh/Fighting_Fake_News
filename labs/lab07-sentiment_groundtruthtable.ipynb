{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sia = SIA()\n",
    "\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "#file for punkt splitter\n",
    "nltk.download('punkt');\n",
    "#file for vader sentiment\n",
    "nltk.download('vader_lexicon');\n",
    "\n",
    "#wordnet lemmatization\n",
    "nltk.download('wordnet')\n",
    "#more for preprocessing\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=20,20\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1: Load the dataset <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21417\n"
     ]
    }
   ],
   "source": [
    "dataset_path_true = os.path.join(\"sources\", \"ISOT\", \"True.csv\")\n",
    "dataset_path_fake = os.path.join(\"sources\", \"ISOT\", \"Fake.csv\")\n",
    "\n",
    "df_true = pd.read_csv(dataset_path_true, encoding='utf-8') # make sure to use the right encoding\n",
    "df_fake = pd.read_csv(dataset_path_fake, encoding='utf-8') \n",
    "\n",
    "dfm_true = df_true.head()\n",
    "dfm_fake = df_fake.head()\n",
    "\n",
    "display(dfm_true)\n",
    "display(dfm_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2: Split the text into sentences <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "\n",
    "in lab 03 we used a big manual function, but for now we will use the nltk tokenizer here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     WASHINGTON (Reuters) - The head of a conservat...\n",
       "1     In keeping with a sharp pivot under way among ...\n",
       "28    The package far exceeded the $44 billion reque...\n",
       "29             The Senate has not yet voted on the aid.\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_sentences(article_text):\n",
    "    \"\"\"Takes a string, returns a list of its individual sentences ()\"\"\"\n",
    "    return pd.Series(nltk.tokenize.sent_tokenize(article_text))\n",
    "\n",
    "sample_sentences = split_sentences(dfm_true.text[0])\n",
    "display(sample_sentences.iloc[[0,1,-2,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Corpus of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sentences = [] # a list of all documents (by sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Corpus of Entire Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of documents in corpus:  44898\n"
     ]
    }
   ],
   "source": [
    "corpus_texts = [] # list of all documents (by entire body)\n",
    "\n",
    "#corpus_texts = df_true['text'].tolist() + df_fake['text'].tolist() \n",
    "corpus_texts = df_true['text'].tolist() + df_fake['text'].tolist() \n",
    "\n",
    "print(\"amount of documents in corpus: \", len(corpus_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3 Text Preprocessing\n",
    "In order to do proper topic analysis the text needs to become understandable by removing unineteresting properties of the text. We lower case it, stem and lemmatize it, and remove all words under 3 characters or stopwords (it them ...).\n",
    "\n",
    "Now with bi and tri grams!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lemmatize(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['follow', 'statement', 'post', 'verifi', 'twitter', 'account', 'presid', 'donald', 'trump', 'realdonaldtrump', 'potu', 'opinion', 'express', 'reuter', 'edit', 'statement', 'confirm', 'accuraci', 'realdonaldtrump', 'fake', 'news', 'love', 'talk', 'call', 'approv', 'rat', 'foxandfriend', 'show', 'rat', 'approxim', 'presid', 'obama', 'despit', 'massiv', 'neg', 'trump', 'coverag', 'russia', 'hoax', 'unit', 'state', 'post', 'offic', 'lose', 'billion', 'dollar', 'year', 'charg', 'amazon', 'littl', 'deliv', 'packag', 'make', 'amazon', 'richer', 'post', 'offic', 'dumber', 'poorer', 'charg', 'sourc', 'link', 'jpexyr']\n"
     ]
    }
   ],
   "source": [
    "def prepare_text(text):\n",
    "    #all the nice preprocessing without the bigrams and trigrams\n",
    "    output = []\n",
    "    \n",
    "    \n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            output.append(stem_lemmatize(token))\n",
    "    return output\n",
    "\n",
    "print(prepare_text(corpus_texts[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['follow', 'statement', 'post', 'verifi', 'twitter', 'account', 'presid', 'donald', 'trump', 'realdonaldtrump', 'potu', 'opinion', 'express', 'reuter', 'edit', 'statement', 'confirm', 'accuraci', 'realdonaldtrump', 'fake', 'news', 'love', 'talk', 'call', 'approv', 'rat', 'foxandfriend', 'show', 'rat', 'approxim', 'presid', 'obama', 'despit', 'massiv', 'neg', 'trump', 'coverag', 'russia', 'hoax', 'unit', 'state', 'post', 'offic', 'lose', 'billion', 'dollar', 'year', 'charg', 'amazon', 'littl', 'deliv', 'packag', 'make', 'amazon', 'richer', 'post', 'offic', 'dumber', 'poorer', 'charg', 'sourc', 'link', 'jpexyr']\n"
     ]
    }
   ],
   "source": [
    "prepared_corpus_texts = [prepare_text(d) for d in corpus_texts]\n",
    "print(processed_corpus_texts[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram = gensim.models.Phrases(processed_corpus_texts, min_count=5, threshold=20) # 5 and 10 are the default values, but this can be tweaked\n",
    "trigram = gensim.models.Phrases(bigram[processed_corpus_texts], threshold=20)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['washington_reuter', 'transgend_peopl', 'allow', 'time', 'enlist', 'militari', 'start', 'monday', 'order', 'feder', 'court', 'pentagon', 'say', 'friday', 'presid', 'donald_trump', 'administr', 'decid', 'appeal', 'rule', 'block', 'transgend', 'feder_appeal_court', 'washington', 'virginia', 'week', 'reject', 'administr', 'request', 'hold', 'order', 'lower_court_judg', 'requir', 'militari', 'begin', 'accept_transgend_recruit', 'justic_depart', 'offici', 'say', 'administr', 'challeng', 'rule', 'depart', 'defens', 'announc', 'releas', 'independ', 'studi', 'issu', 'come', 'week', 'litig', 'interim', 'appeal', 'occur', 'administr', 'decid', 'wait', 'studi', 'continu', 'defend', 'presid', 'law', 'author', 'district_court', 'meantim', 'offici', 'say', 'speak_condit_anonym', 'septemb', 'pentagon', 'say', 'creat', 'panel', 'senior', 'offici', 'studi', 'implement', 'direct', 'trump', 'prohibit', 'transgend_individu_serv', 'defens', 'depart', 'submit', 'plan', 'trump', 'lawyer', 'repres', 'current', 'serv', 'transgend', 'servic', 'member', 'aspir', 'recruit', 'say', 'expect', 'administr', 'appeal', 'rule', 'conserv', 'major', 'suprem_court', 'hop', 'happen', 'pentagon', 'spokeswoman_heather', 'babb', 'say', 'statement', 'mandat', 'court', 'order', 'depart', 'defens', 'prepar', 'begin', 'access', 'transgend', 'applic', 'militari', 'servic', 'applic', 'meet', 'access', 'standard', 'jennif', 'levi', 'lawyer', 'lesbian_transgend', 'advocaci_group', 'glad', 'call', 'decis', 'appeal', 'great', 'news', 'hop', 'mean', 'govern', 'come', 'justifi', 'good', 'militari', 'countri', 'levi', 'say', 'glad', 'american_civil_liberti', 'union', 'repres', 'plaintiff', 'lawsuit_file', 'administr', 'appeal', 'hard_line_conserv', 'support', 'trump', 'announc', 'juli', 'prohibit', 'transgend_peopl', 'serv', 'militari', 'revers', 'democrat', 'presid_barack_obama', 'polici', 'accept', 'trump', 'say', 'twitter', 'time', 'militari', 'burden_tremend_medic', 'cost_disrupt_transgend', 'militari_entail', 'feder_judg', 'baltimor', 'washington', 'seattl', 'riversid', 'california', 'issu', 'rule', 'block', 'trump', 'legal_challeng', 'republican', 'presid', 'polici', 'proceed', 'judg', 'say', 'like', 'violat', 'right', 'constitut', 'equal_protect', 'pentagon', 'issu', 'guidelin', 'recruit', 'personnel', 'order', 'enlist', 'transgend', 'applic', 'memo', 'outlin', 'medic', 'requir', 'specifi', 'applic', 'identifi', 'undergar', 'wear', 'trump', 'administr', 'previous', 'say', 'legal', 'paper', 'arm_forc', 'prepar', 'train', 'thousand', 'personnel', 'medic', 'standard', 'need', 'process', 'transgend', 'applic', 'accept', 'individu', 'medic', 'servic', 'obama_administr', 'deadlin', 'juli', 'begin', 'accept_transgend_recruit', 'trump', 'defens_secretari_jam_matti', 'postpon', 'date', 'presid', 'indefinit', 'trump', 'take', 'step', 'aim', 'roll', 'transgend', 'right', 'octob', 'administr', 'say', 'feder', 'ban', 'gender', 'base', 'workplac', 'discrimin', 'protect', 'transgend', 'employe', 'revers', 'obama', 'posit', 'februari', 'trump', 'rescind', 'guidanc', 'issu', 'obama_administr', 'say', 'public', 'school', 'allow_transgend_student', 'restroom_correspond', 'gender_ident']]\n",
      "\n",
      "\n",
      "\n",
      "['donald_trump']\n"
     ]
    }
   ],
   "source": [
    "print(make_trigrams([prepared_corpus_texts[1]]))\n",
    "print(\"\\n\\n\")\n",
    "print(trigram_mod[bigram_mod[preprocess(\"donald trump\")]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return(trigram_mod[bigram_mod[prepare_text(text)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4 Dictionary Creation\n",
    "\n",
    "word embeddings, all occuring words are stored and get a number (embedding) those embeddings can later be used for vector calculations. of course not all words are important, so words that appear more than 100000 times or that exist in >60%  our corpus (those are very likely words slipped the stopword list) and less than 15 time (words not important enought for a topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfiltered:  Dictionary(116439 unique tokens: ['administr', 'agre', 'aid', 'approach', 'approv']...)\n",
      "  filtered:  Dictionary(21592 unique tokens: ['administr', 'agre', 'aid', 'approach', 'approv']...)\n",
      "Wall time: 45.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating the gensim dictionary of word embeddings\n",
    "\n",
    "if (0):\n",
    "    dictionary = gensim.corpora.Dictionary.load(os.path.join(\"gensim\", \"dictionary\"))\n",
    "\n",
    "if (0):\n",
    "    \n",
    "    processed_corpus_texts = [trigram_mod[bigram_mod[doc]] for doc in prepared_corpus_texts]\n",
    "\n",
    "    dictionary = gensim.corpora.Dictionary(processed_corpus_texts)\n",
    "    print(\"unfiltered: \", dictionary)\n",
    "\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.6, keep_n=100000)\n",
    "    \n",
    "print(\"  filtered: \", dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5 Bag of Words creation\n",
    "Now we create a vector representation in the form of a bag of words for eacht document. a vector that lets us know how often each word in the preprocessed text, that also exists in our dictionary, occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if (0):\n",
    "    with open('bag_of_words.pickle', 'rb') as f: dictionary = pickle.load(f)\n",
    "\n",
    "if (0):\n",
    "    bow_corpus_texts = [dictionary.doc2bow(text) for text in processed_corpus_texts]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6 LDA model creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_topics = 15\n",
    "if (0):\n",
    "    lda_model = gensim.models.LdaMulticore.load(os.path.join(\"gensim\", \"lda_model20\"))\n",
    "if (0):\n",
    "    lda_modelX = gensim.models.LdaMulticore(corpus = bow_corpus_texts,\n",
    "                                            id2word = dictionary,\n",
    "                                            num_topics = num_topics,\n",
    "                                            passes = 20,\n",
    "                                            iterations = 200,\n",
    "                                            eta = 'auto',\n",
    "                                            #alpha = 'auto',\n",
    "                                            workers = 2)\n",
    "    # multicore speeds up the process significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 7 TF-IDF x LDA model creation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "tfidf_model = gensim.models.TfidfModel(bow_corpus_texts)\n",
    "tfidf_corpus_texts = tfidf_model[bow_corpus_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_topics = 15\n",
    "\n",
    "if (0):\n",
    "    lda_tfidf_model = gensim.models.LdaMulticore(corpus = tfidf_corpus_texts,\n",
    "                                        id2word = dictionary,\n",
    "                                        num_topics = num_topics,\n",
    "                                        passes = 20,\n",
    "                                        iterations = 200,\n",
    "                                        eta = 'auto',\n",
    "                                        #alpha = 'auto', # not available form multicore\n",
    "                                        workers = 2)\n",
    "if (0):\n",
    "    lda_tfidf_model.save(os.path.join(\"gensim\", \"02\", \"lda_model\")) #save model itself\n",
    "    with open(os.path.join(\"gensim\", \"02\", \"tfidf_corpus.pickle\"), 'wb') as f: pickle.dump(tfidf_corpus_texts, f)    #dump tfidf_corpus_texts\n",
    "    dictionary.save(os.path.join(\"gensim\", \"02\", \"dictionary\")) #save dictionary\n",
    "\n",
    "# multicore speeds up the process significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.47852099608521953\n",
      "\n",
      "Coherence Score:  0.5345937527916345\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import CoherenceModel# Compute Coherence Score\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_modelX, texts=processed_corpus_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "coherence_model_lda_tfidf = CoherenceModel(model=lda_tfidf_model, texts=processed_corpus_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_tfidf = coherence_model_lda_tfidf.get_coherence()\n",
    "\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "print('\\nCoherence Score: ', coherence_lda_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 8 Case Examination\n",
    "take a look at some classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO LDAVIS For TWEAKING SHIT SAVE PICTURES AND STEPS WHOOO\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "visualisation = pyLDAvis.gensim.prepare(lda_model50, bow_corpus_texts, dictionary)\n",
    "pyLDAvis.save_html(visualisation, os.path.join(\"gensim\", \"LDAvis\", \"LDAvis.hml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "most frequently occuring word:  trump\n",
      "\n",
      "\n",
      "bow-lda prediction:\n",
      "\n",
      "Score: 0.5868434309959412\t \n",
      "Topic: 0.014*\"like\" + 0.013*\"peopl\" + 0.011*\"know\" + 0.011*\"go\" + 0.010*\"think\" + 0.010*\"obama\" + 0.009*\"presid\" + 0.009*\"american\" + 0.009*\"trump\" + 0.008*\"time\"\n",
      "\n",
      "Score: 0.29268181324005127\t \n",
      "Topic: 0.161*\"trump\" + 0.039*\"presid\" + 0.026*\"clinton\" + 0.024*\"donald_trump\" + 0.017*\"campaign\" + 0.016*\"white_hous\" + 0.010*\"report\" + 0.008*\"hillari_clinton\" + 0.008*\"http\" + 0.008*\"tell\"\n",
      "\n",
      "Score: 0.09060100466012955\t \n",
      "Topic: 0.012*\"year\" + 0.011*\"republican\" + 0.009*\"million\" + 0.009*\"plan\" + 0.009*\"fund\" + 0.008*\"congress\" + 0.007*\"hous\" + 0.007*\"american\" + 0.007*\"state\" + 0.007*\"govern\"\n",
      "\n",
      "Score: 0.022879285737872124\t \n",
      "Topic: 0.015*\"women\" + 0.014*\"black\" + 0.011*\"protest\" + 0.010*\"student\" + 0.010*\"white\" + 0.009*\"support\" + 0.008*\"school\" + 0.008*\"video\" + 0.007*\"twitter\" + 0.007*\"peopl\"\n",
      "\n",
      "\n",
      "tfidf-lda prediction:\n",
      "\n",
      "Score: 0.8023303151130676\t \n",
      "Topic: 0.005*\"trump\" + 0.003*\"obama\" + 0.002*\"american\" + 0.002*\"peopl\" + 0.002*\"clinton\" + 0.002*\"presid\" + 0.002*\"like\" + 0.002*\"elect\" + 0.002*\"hillari\" + 0.002*\"parti\"\n",
      "\n",
      "Score: 0.0666574165225029\t \n",
      "Topic: 0.009*\"wire\" + 0.007*\"cuba\" + 0.007*\"cuban\" + 0.007*\"assang\" + 0.006*\"berni_sander\" + 0.005*\"berni\" + 0.005*\"white_helmet\" + 0.005*\"broadcast_live\" + 0.004*\"meme\" + 0.004*\"julian_assang\"\n",
      "\n",
      "Score: 0.02224014885723591\t \n",
      "Topic: 0.032*\"deep_state\" + 0.021*\"hanniti\" + 0.007*\"gorka\" + 0.007*\"undercov\" + 0.007*\"oligarch\" + 0.006*\"russian_collus\" + 0.006*\"kimmel\" + 0.006*\"khan\" + 0.006*\"pakistan\" + 0.005*\"hernandez\"\n",
      "\n",
      "Score: 0.020426075905561447\t \n",
      "Topic: 0.009*\"moor\" + 0.008*\"reilli\" + 0.008*\"conway\" + 0.007*\"funni\" + 0.005*\"bannon\" + 0.005*\"hammond\" + 0.005*\"savag\" + 0.004*\"kellyann_conway\" + 0.004*\"warren\" + 0.004*\"kushner\"\n",
      "\n",
      "\n",
      " ['hous', 'card', 'star', 'kevin_spacey', 'play', 'fiction_charact', 'presid', 'frank_underwood', 'cnbc', 'intern', 'thursday', 'couldn', 'avoid', 'get', 'ask', 'question', 'concern', 'presidenti_elect', 'chief', 'question', 'happen', 'donald_trump', 'debat', 'frank_underwood', 'answer', 'give', 'draw_laughter', 'wouldn', 'debat', 'underwood', 'terribl', 'accid', 'debat', 'terribl', 'wasn', 'funni', 'follow', 'best', 'trump', 'imperson', 'huuug', 'huge', 'church', 'spacey', 'current', 'make', 'round', 'globe', 'promot', 'upcom', 'season', 'hous', 'card', 'air', 'march', 'ask', 'question', 'annual', 'skybridg_capit', 'recept', 'host', 'piano', 'earlier', 'say', 'get', 'ask', 'question', 'happen', 'frank_underwood', 'debat', 'trump', 'think', 'say', 'rememb', 'import', 'distinct', 'charact', 'fiction_charact', 'fiction_charact', 'turn', 'line', 'past', 'probabl', 'best', 'elabor', 'answer', 'provid', 'session', 'septemb', 'think', 'underwood', 'kill', 'donald_trump', 'trump', 'elect', 'think', 'great', 'donald_trump', 'start', 'feud', 'fiction_charact', 'mayb', 'fair', 'fight', 'trump', 'appear', 'season', 'hous', 'card', 'year', 'lose', 'real', 'elect', 'novemb', 'person', 'fetch', 'trump', 'rival', 'frank_underwood', 'featur_imag_screen_captur'] \n",
      "\n",
      " House of Cards star Kevin Spacey, who plays the fictional character President Frank Underwood, sat down with CNBC International on Thursday and just couldn t avoid getting asked questions concerning the 2016 presidential election. Chief among them was a question about what would happen if Donald Trump ever had to debate Frank Underwood.Here is the answer he gave, which drew quite a bit of laughter: He wouldn t (debate Underwood). There would be a terrible accident, on the way to the debate. It would be terrible, and very sad. If that wasn t funny enough, he followed that up with his best Trump impersonation: I m huuuge. I m too huge for this church. Spacey is currently making rounds across the globe promoting the new upcoming season of House of Cards, which airs in March. He was also asked this very same question at the annual SkyBridge Capital reception hosted at a piano bar just a day earlier. He says he often gets asked the question of what would happen if Frank Underwood had to debate Trump,  who would win? I thought about this and I said,  We must remember one important distinction, one of these characters is a fictional character, and the other is a fictional character.' It turns out he s used this line in the past often. Probably the best and most elaborate answer he s ever provided is from a Q & A session with CNN he did back in September. Oh, I think Underwood (would win). He (would win) because he would kill Donald Trump. Trump would never make it to election day. It d be over, done.I think it would be great if Donald Trump started a feud with a fictional character, because maybe for once it would be a fair fight. Perhaps Trump will appear in season 5 of House of Cards next year after he loses the real U.S. election this November. He is, after all, a TV personality. It s not too far-fetched that Trump could be a rival of Frank Underwood one day.Featured image via screen capture.\n"
     ]
    }
   ],
   "source": [
    "article = 30000\n",
    "\n",
    "print(\"\\nmost frequently occuring word: \", max(preprocess(corpus_texts[article]),key=preprocess(corpus_texts[article]).count))\n",
    "\n",
    "print(\"\\n\\nbow-lda prediction:\")\n",
    "\n",
    "for index, score in sorted(lda_modelX[bow_corpus_texts[article]],\n",
    "                           key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_modelX.print_topic(index, 10)))\n",
    "\n",
    "print(\"\\n\\ntfidf-lda prediction:\")\n",
    "\n",
    "for index, score in sorted(lda_tfidf_model[tfidf_corpus_texts[article]],\n",
    "                           key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_tfidf_model.print_topic(index, 10)))\n",
    "    \n",
    "print(\"\\n\\n\", preprocess(corpus_texts[article]), \"\\n\\n\", corpus_texts[article])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## X Saving items\n",
    "because we dont want to sit waiting every time please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (0):\n",
    "    lda_modelXX.save(os.path.join(\"gensim\", \"lda_modelXX\"))\n",
    "    with open(os.path.join(\"gensim\", \"bag_of_words.pickle\"), 'wb') as f: pickle.dump(bow_corpus_texts, f)    \n",
    "    dictionary.save(os.path.join(\"gensim\", \"dictionary\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 10: Performing sentiment analysis <a class=\"anchor\" id=\"chapter3\"></a>\n",
    "Which we can do either to the whole article or on a sentence basis and then average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(text: list, method='VADER'):\n",
    "    if method == 'VADER':\n",
    "        scores = text.apply(lambda s: sia.polarity_scores(s)['compound']) #list of compound score per sentence\n",
    "    else:\n",
    "        scores = None\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10535714285714284"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_sentiment(doc):\n",
    "    doc_sentence_list = split_sentences(doc)\n",
    "    return float(np.average(get_scores(doc_sentence_list)))\n",
    "\n",
    "average_sentiment(corpus_texts[10005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as can be seen in the following cell the entire document sentiment gives crazy extreme and unnuanced values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9153 \n",
      "\n",
      " 0.10535714285714284 \n",
      "\n",
      "from:\n",
      " 0     0.4588\n",
      "1    -0.3818\n",
      "2    -0.3818\n",
      "3     0.4019\n",
      "4     0.0000\n",
      "5     0.0000\n",
      "6     0.1779\n",
      "7     0.1531\n",
      "8     0.8442\n",
      "9     0.4215\n",
      "10   -0.2960\n",
      "11    0.0000\n",
      "12    0.0772\n",
      "13    0.0000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "article = 10005\n",
    "\n",
    "sample_article = corpus_texts[article]\n",
    "sample_sentences = split_sentences(sample_article)\n",
    "\n",
    "sample_scoreT = sia.polarity_scores(sample_article)['compound']\n",
    "sample_scoreS = get_scores(sample_sentences)\n",
    "\n",
    "print(sample_scoreT, \"\\n\\n\", average_sentiment(sample_article), \"\\n\\nfrom:\\n\", sample_scoreS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 0.07614666666666665, 'T0': 0, 'T1': 0, 'T2': 0, 'T3': 0, 'T4': 0, 'T5': 0, 'T6': 0, 'T7': 0, 'T8': 0, 'T9': 0, 'T10': 0.026416631, 'T11': 0, 'T12': 0, 'T13': 0.8555344, 'T14': 0.054770425, 'Veracity': 1}\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "topic_cols = ['Sentiment']+[('T'+str(x)) for x in range(0, num_topics)]+['Veracity']\n",
    "# text to list of topic scores\n",
    "\n",
    "def docid_to_row(doc_id):\n",
    "    new_row = dict.fromkeys(topic_cols , 0)\n",
    "    \n",
    "    new_row['Sentiment'] = average_sentiment(corpus_texts[doc_id])\n",
    "    for index, score in lda_tfidf_model[tfidf_corpus_texts[doc_id]]:\n",
    "        new_row['T'+str(index)] = score\n",
    "    if(doc_id<21417):\n",
    "        new_row['Veracity'] = 1\n",
    "    return(new_row)\n",
    "\n",
    "print(docid_to_row(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_topic_sentiment = pd.DataFrame(columns=topic_cols)\n",
    "\n",
    "for doc_id in range(len(corpus_texts)):\n",
    "    df_topic_sentiment = df_topic_sentiment.append(docid_to_row(doc_id), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sentiment.to_csv(os.path.join('out', 'topic_sentiment.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_notebook",
   "language": "python",
   "name": "thesis_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
